{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import KFold, cross_validate, train_test_split, LeaveOneOut\n",
    "from surprise import accuracy\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the default prediction function for the TOP-N Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase\n",
    "from surprise.prediction_algorithms.predictions import PredictionImpossible\n",
    "from six import iteritems\n",
    "import heapq\n",
    "\n",
    "class SymmetricAlgo(AlgoBase):\n",
    "    \"\"\"This is an abstract class aimed to ease the use of symmetric algorithms.\n",
    "    A symmetric algorithm is an algorithm that can can be based on users or on\n",
    "    items indifferently, e.g. all the algorithms in this module.\n",
    "    When the algo is user-based x denotes a user and y an item. Else, it's\n",
    "    reversed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        ub = self.sim_options['user_based']\n",
    "        self.n_x = self.trainset.n_users if ub else self.trainset.n_items\n",
    "        self.n_y = self.trainset.n_items if ub else self.trainset.n_users\n",
    "        self.xr = self.trainset.ur if ub else self.trainset.ir\n",
    "        self.yr = self.trainset.ir if ub else self.trainset.ur\n",
    "\n",
    "        return self\n",
    "\n",
    "    def switch(self, u_stuff, i_stuff):\n",
    "        \"\"\"Return x_stuff and y_stuff depending on the user_based field.\"\"\"\n",
    "\n",
    "        if self.sim_options['user_based']:\n",
    "            return u_stuff, i_stuff\n",
    "        else:\n",
    "            return i_stuff, u_stuff\n",
    "\n",
    "\n",
    "class RankingKNN(SymmetricAlgo):\n",
    "\n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        SymmetricAlgo.__init__(self, sim_options=sim_options,\n",
    "                               verbose=verbose, **kwargs)\n",
    "\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "        self.sim = self.compute_similarities()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unknown.')\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "        neighbors = [(x2, self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "        est = 0\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = actual_k = 0\n",
    "        for (nb, sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                actual_k += 1\n",
    "\n",
    "        if actual_k < self.min_k:\n",
    "            est = 0\n",
    "        else:\n",
    "            est += sum_sim\n",
    "\n",
    "        details = {'actual_k': actual_k}\n",
    "        return est, details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ub_algo = RankingKNN(k=80, min_k=5, sim_options={'name': 'cosine', 'user_based': True})\n",
    "#ib_algo = RankingKNN(k=80, min_k=5, sim_options={'name': 'cosine', 'user_based': False})\n",
    "ub_algo = KNNWithMeans(k=60, min_k=5, sim_options={'name': 'pearson_baseline', 'shrinkage': 50, 'user_based': True})\n",
    "ib_algo = KNNWithMeans(k=40, min_k=5, sim_options={'name': 'pearson_baseline', 'shrinkage': 50, 'user_based': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userID  itemID  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "\n",
      "\n",
      "\n",
      "   userID  itemID  rating  timeStamp\n",
      "0       5     648       5  978297876\n",
      "1       5    1394       5  978298237\n",
      "2       5    3534       5  978297149\n",
      "3       5     104       4  978298558\n",
      "4       5    2735       5  978297919\n"
     ]
    }
   ],
   "source": [
    "# Read both the datasets from the files using pandas\n",
    "movielens_df = pd.read_csv(\"../data/u.data\", sep=\"\\t\", header=None)\n",
    "movielens_df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    "pda_df = pd.read_csv(\"../data/train-PDA2018.csv\", sep=\",\")\n",
    "print(movielens_df.head())\n",
    "print(\"\\n\\n\")\n",
    "print(pda_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes before sub-sampling:\n",
      "(100000, 4)\n",
      "(470711, 4)\n",
      "\n",
      "Shapes after sub-sampling:\n",
      "(97623, 4)\n",
      "(465154, 4)\n"
     ]
    }
   ],
   "source": [
    "# Sample the data such that every user has rated at least 10 items and every item has been by at least 10 users\n",
    "print(\"Shapes before sub-sampling:\")\n",
    "print(movielens_df.shape)\n",
    "print(pda_df.shape)\n",
    "\n",
    "# Movielens users all have at least 20 ratings so no need to subsample the user values\n",
    "ml_subsampled = movielens_df[movielens_df['itemID'].isin(movielens_df['itemID'].value_counts()[movielens_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_df[pda_df['itemID'].isin(pda_df['itemID'].value_counts()[pda_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_subsampled[pda_subsampled['userID'].isin(pda_subsampled['userID'].value_counts()[pda_subsampled['userID'].value_counts()>10].index)]\n",
    "print(\"\\nShapes after sub-sampling:\")\n",
    "print(ml_subsampled.shape)\n",
    "print(pda_subsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information on the training sets we will be using \n",
      "\n",
      "1) Number of items in each dataset  ML100k: 1119 PDA: 1753\n",
      "2) Number of users in each dataset  ML100k: 943 PDA: 4706\n",
      "3) Number of ratings in each dataset  ML100k: 78098 PDA: 372123\n",
      "4) Mean rating  ML100k: 3.5481062255115368 PDA: 3.6341102269948378\n"
     ]
    }
   ],
   "source": [
    "# Create the training datasets using Surprise's reader class\n",
    "reader = Reader(rating_scale=(1,5)) # We have ratings from 1 to 5 so we create the rating scale\n",
    "\n",
    "# Load the data from the dataframes\n",
    "movielens_dataset = Dataset.load_from_df(ml_subsampled.iloc[:,0:3], reader)\n",
    "pda_dataset = Dataset.load_from_df(pda_subsampled.iloc[:,0:3], reader)\n",
    "\n",
    "# Build full trainsets to print out the data loaded above\n",
    "# mls_train = movielens_dataset.build_full_trainset()\n",
    "# pda_train = pda_dataset.build_full_trainset()\n",
    "mls_train, mls_test = train_test_split(data=movielens_dataset, test_size=0.2)\n",
    "pda_train, pda_test = train_test_split(data=pda_dataset, test_size=0.2)\n",
    "\n",
    "# Print out some basic information about the datasets\n",
    "print(\"General information on the training sets we will be using \\n\")\n",
    "print(\"1) Number of items in each dataset\", \" ML100k:\", mls_train.n_items, \"PDA:\", pda_train.n_items)\n",
    "print(\"2) Number of users in each dataset\", \" ML100k:\", mls_train.n_users, \"PDA:\", pda_train.n_users)\n",
    "print(\"3) Number of ratings in each dataset\", \" ML100k:\", mls_train.n_ratings, \"PDA:\", pda_train.n_ratings)\n",
    "print(\"4) Mean rating\", \" ML100k:\", mls_train.global_mean, \"PDA:\", pda_train.global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have ratings in the train set for all the users in the test set\n",
    "items_not_in_train = []\n",
    "for _,itemId, _ in mls_test:    \n",
    "    if itemId not in mls_train.ir.keys():\n",
    "        items_not_in_train.append(itemId)\n",
    "        \n",
    "def user_seen_items(userId):\n",
    "    return [train_itemId for train_itemId, rating in mls_train.ur[userId]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data to the model and generate rating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648</td>\n",
       "      <td>746</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.628166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>511</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.973553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.043833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293</td>\n",
       "      <td>199</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.717179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>284</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.487037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19520</th>\n",
       "      <td>450</td>\n",
       "      <td>164</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.864094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19521</th>\n",
       "      <td>6</td>\n",
       "      <td>496</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.217721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19522</th>\n",
       "      <td>255</td>\n",
       "      <td>447</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.982379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19523</th>\n",
       "      <td>735</td>\n",
       "      <td>321</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.897516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>49</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.446889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19525 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  iid  r_ui       est\n",
       "0      648  746   4.0  3.628166\n",
       "1      198  511   4.0  3.973553\n",
       "2      360    1   3.0  4.043833\n",
       "3      293  199   5.0  3.717179\n",
       "4      115  284   2.0  3.487037\n",
       "...    ...  ...   ...       ...\n",
       "19520  450  164   4.0  3.864094\n",
       "19521    6  496   4.0  4.217721\n",
       "19522  255  447   3.0  2.982379\n",
       "19523  735  321   3.0  2.897516\n",
       "19524   49  111   2.0  2.446889\n",
       "\n",
       "[19525 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_algo.fit(mls_train)\n",
    "predictions = ub_algo.test(mls_test)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df = predictions_df.iloc[:,:-1] \n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-N Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n, minimumRating, criterion):\n",
    "    topN = defaultdict(list)\n",
    "    \n",
    "    for index, row in predictions.iterrows():\n",
    "        if (row[criterion] >= minimumRating):\n",
    "            topN[int(row.uid)].append((int(row.iid), row[criterion]))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions_df, n=k, minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions_df, n=k, minimumRating=threshold, criterion=\"r_ui\")\n",
    "    above_threshold = predictions_df[predictions_df.r_ui >= threshold]\n",
    "\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "\n",
    "    for uid, est_topn in top_n_recoms_est.items():\n",
    "        # Get items the user has already rated\n",
    "        already_seen = user_seen_items(uid)\n",
    "        # Get relevant items for the user\n",
    "        n_rel_for_user = len(above_threshold[above_threshold.uid == uid])        \n",
    "        tp = 0\n",
    "        # Penalize the scores if:\n",
    "        # - The item we are recommending was never seen in the training set (how could we recommend what we don't know?)\n",
    "        # - The user has already rated this item: It's not a good recommendation since the user already knows it/has seen it\n",
    "        for est_itemId, _ in est_topn:\n",
    "            if(est_itemId in items_not_in_train or est_itemId in already_seen):\n",
    "                tp += 0\n",
    "            else:\n",
    "                for real_itemId, _ in top_n_recoms_real[uid]:\n",
    "                    if (est_itemId == real_itemId):\n",
    "                        tp +=1\n",
    "        \n",
    "        precisions[uid] = tp/k\n",
    "        recalls[uid] = tp/n_rel_for_user if n_rel_for_user != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "def ndcg_for_rec(predictions, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"r_ui\")\n",
    "    ndcgs = {}\n",
    "\n",
    "    for uid, real_topn in top_n_recoms_real.items():\n",
    "        user_gt = [true_rating[0] for true_rating in real_topn]\n",
    "        est_top_for_current = top_n_recoms_est[uid]\n",
    "        predicted_items = [est_rating[0] for est_rating in est_top_for_current]\n",
    "        predicted_scores = [est_rating[1] for est_rating in est_top_for_current]\n",
    "        gain_scores = np.zeros(len(user_gt)).tolist()\n",
    "\n",
    "        ndcg_val = 0\n",
    "        \n",
    "        if(len(predicted_items) == 0):\n",
    "            ndcg_val += 0\n",
    "        elif(len(predicted_items) == 1 or len(user_gt) == 1):\n",
    "            if(predicted_items[0] == user_gt[0]):\n",
    "                ndcg_val += 1\n",
    "        else:\n",
    "            for i, pred_item in enumerate(predicted_items):\n",
    "                for j, gt_item in enumerate(user_gt):\n",
    "                    if(gt_item==pred_item):\n",
    "                        gain_scores[j] = i\n",
    "            gain_scores =[int(elem) for elem in gain_scores]\n",
    "            ndcg_val += ndcg_score(np.asarray([user_gt]), np.asarray([gain_scores]))\n",
    "            \n",
    "        #print(\"GT:\", user_gt)\n",
    "        #print(\"Pred:\", predicted_items)\n",
    "        #print(gain_scores)\n",
    "        #print( \"\\n\\n\")\n",
    "        ndcgs[uid] = ndcg_val\n",
    "\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pres_at_5, recalls_at_5 = precision_recall_at_k(predictions_df, k=5)\n",
    "#pres_at_10, recalls_at_10 = precision_recall_at_k(predictions_df, k=10)\n",
    "ndcgs = ndcg_for_rec(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and Recall @5: 0.36523754345307075 0.32982892985517315\n",
      "Precision and Recall @10: 0.36326767091541134 0.48000042990615494\n",
      "NDCG: 0.7041892827871443\n"
     ]
    }
   ],
   "source": [
    "avg_pre_5 = np.array([pres_at_5[k] for k in pres_at_5.keys()]).mean()\n",
    "avg_rec_5 = np.array([recalls_at_5[k] for k in recalls_at_5.keys()]).mean()\n",
    "print(\"Precision and Recall @5:\", avg_pre_5, avg_rec_5)\n",
    "avg_pre_10 = np.array([pres_at_10[k] for k in pres_at_10.keys()]).mean()\n",
    "avg_rec_10 = np.array([recalls_at_10[k] for k in recalls_at_10.keys()]).mean()\n",
    "print(\"Precision and Recall @10:\", avg_pre_10, avg_rec_10)\n",
    "avg_ndcg = np.array([ndcgs[k] for k in ndcgs.keys()]).mean()\n",
    "print(\"NDCG:\", avg_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
